{"dependencies":[{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/package.json","includedInParent":true,"mtime":1533242702575},{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/.babelrc","includedInParent":true,"mtime":1533242702523},{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/node_modules/@tensorflow/tfjs-core/package.json","includedInParent":true,"mtime":1533242741391},{"name":"../doc","loc":{"line":7,"column":20}},{"name":"../tracking","loc":{"line":8,"column":25}},{"name":"../util","loc":{"line":9,"column":23}},{"name":"./operation","loc":{"line":10,"column":26}},{"name":"./ops","loc":{"line":11,"column":49}}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\nexports.LinalgOps = undefined;\n\nvar _doc = require(\"../doc\");\n\nvar _tracking = require(\"../tracking\");\n\nvar _util = require(\"../util\");\n\nvar _operation = require(\"./operation\");\n\nvar _ops = require(\"./ops\");\n\nvar __decorate = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n    var c = arguments.length,\n        r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n        d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\n\nvar LinalgOps = function () {\n    function LinalgOps() {}\n    LinalgOps.gramSchmidt = function (xs) {\n        var inputIsTensor2D;\n        if (Array.isArray(xs)) {\n            inputIsTensor2D = false;\n            (0, _util.assert)(xs != null && xs.length > 0, 'Gram-Schmidt process: input must not be null, undefined, or empty');\n            var dim = xs[0].shape[0];\n            for (var i = 1; i < xs.length; ++i) {\n                (0, _util.assert)(xs[i].shape[0] === dim, 'Gram-Schmidt: Non-unique lengths found in the input vectors: ' + (\"(\" + xs[i].shape[0] + \" vs. \" + dim + \")\"));\n            }\n        } else {\n            inputIsTensor2D = true;\n            xs = (0, _ops.split)(xs, xs.shape[0], 0).map(function (x) {\n                return (0, _ops.squeeze)(x, [0]);\n            });\n        }\n        (0, _util.assert)(xs.length <= xs[0].shape[0], \"Gram-Schmidt: Number of vectors (\" + xs.length + \") exceeds \" + (\"number of dimensions (\" + xs[0].shape[0] + \").\"));\n        var ys = [];\n        var xs1d = xs;\n        var _loop_1 = function (i) {\n            ys.push(_tracking.Tracking.tidy(function () {\n                var x = xs1d[i];\n                if (i > 0) {\n                    for (var j = 0; j < i; ++j) {\n                        var proj = (0, _ops.sum)(ys[j].mulStrict(x)).mul(ys[j]);\n                        x = x.sub(proj);\n                    }\n                }\n                return x.div((0, _ops.norm)(x, 'euclidean'));\n            }));\n        };\n        for (var i = 0; i < xs.length; ++i) {\n            _loop_1(i);\n        }\n        if (inputIsTensor2D) {\n            return (0, _ops.stack)(ys, 0);\n        } else {\n            return ys;\n        }\n    };\n    __decorate([(0, _doc.doc)({ heading: 'Operations', subheading: 'Linear Algebra' }), _operation.operation], LinalgOps, \"gramSchmidt\", null);\n    return LinalgOps;\n}();\nexports.LinalgOps = LinalgOps;\n//# sourceMappingURL=linalg_ops.js.map"},"hash":"fbdd8014038940a3bf6da2a4ecc4c76a","cacheData":{"env":{}}}