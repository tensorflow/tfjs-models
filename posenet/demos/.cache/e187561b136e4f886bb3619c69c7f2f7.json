{"dependencies":[{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/package.json","includedInParent":true,"mtime":1533242702575},{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/.babelrc","includedInParent":true,"mtime":1533242702523},{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":1533242740549},{"name":"@tensorflow/tfjs-core","loc":{"line":12,"column":42}},{"name":"../backend/tfjs_backend","loc":{"line":13,"column":19}},{"name":"../constraints","loc":{"line":14,"column":51}},{"name":"../engine/topology","loc":{"line":15,"column":33}},{"name":"../errors","loc":{"line":16,"column":48}},{"name":"../initializers","loc":{"line":17,"column":53}},{"name":"../regularizers","loc":{"line":18,"column":53}},{"name":"../utils/generic_utils","loc":{"line":19,"column":31}},{"name":"../utils/math_utils","loc":{"line":20,"column":28}}],"generated":{"js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\nexports.BatchNormalization = undefined;\nexports.batchNormalization = batchNormalization;\nexports.normalizeBatchInTraining = normalizeBatchInTraining;\n\nvar _tfjsCore = require('@tensorflow/tfjs-core');\n\nvar tfc = _interopRequireWildcard(_tfjsCore);\n\nvar _tfjs_backend = require('../backend/tfjs_backend');\n\nvar K = _interopRequireWildcard(_tfjs_backend);\n\nvar _constraints = require('../constraints');\n\nvar _topology = require('../engine/topology');\n\nvar _errors = require('../errors');\n\nvar _initializers = require('../initializers');\n\nvar _regularizers = require('../regularizers');\n\nvar _generic_utils = require('../utils/generic_utils');\n\nvar generic_utils = _interopRequireWildcard(_generic_utils);\n\nvar _math_utils = require('../utils/math_utils');\n\nvar math_utils = _interopRequireWildcard(_math_utils);\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\nvar __extends = undefined && undefined.__extends || function () {\n    var extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function (d, b) {\n        d.__proto__ = b;\n    } || function (d, b) {\n        for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() {\n            this.constructor = d;\n        }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n}();\nfunction batchNormalization(x, mean, variance, beta, gamma, epsilon) {\n    if (epsilon === void 0) {\n        epsilon = 1e-3;\n    }\n    var out;\n    if (x.rank === 2) {\n        out = tfc.batchNormalization2d(x, mean, variance, epsilon, gamma, beta);\n    } else if (x.rank === 3) {\n        out = tfc.batchNormalization3d(x, mean, variance, epsilon, gamma, beta);\n    } else if (x.rank === 4) {\n        out = tfc.batchNormalization4d(x, mean, variance, epsilon, gamma, beta);\n    } else {\n        throw new _errors.NotImplementedError(\"batchNormalization is not implememnted for array of rank \" + x.rank + \" \" + \"yet\");\n    }\n    return out;\n}\nfunction regularNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon) {\n    if (epsilon === void 0) {\n        epsilon = 1e-3;\n    }\n    return (0, _tfjsCore.tidy)(function () {\n        var meanAndVariance = tfc.moments(x, reductionAxes);\n        var mean = meanAndVariance.mean;\n        var variance = meanAndVariance.variance;\n        var normed = batchNormalization(x, mean, variance, beta, gamma, epsilon);\n        return [normed, mean, variance];\n    });\n}\nfunction broadcastNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon) {\n    if (epsilon === void 0) {\n        epsilon = 1e-3;\n    }\n    return (0, _tfjsCore.tidy)(function () {\n        var meanAndVariance = tfc.moments(x, reductionAxes);\n        var mean = meanAndVariance.mean;\n        var variance = meanAndVariance.variance;\n        var targetShape = [];\n        for (var _i = 0, _a = math_utils.range(0, x.rank); _i < _a.length; _i++) {\n            var axis = _a[_i];\n            if (reductionAxes.indexOf(axis) !== -1) {\n                targetShape.push(1);\n            } else {\n                targetShape.push(x.shape[axis]);\n            }\n        }\n        var broadcastMean = mean.reshape(targetShape);\n        var broadcastVariance = variance.reshape(targetShape);\n        var broadcastGamma = gamma == null ? null : gamma.reshape(targetShape);\n        var broadcastBeta = beta == null ? null : beta.reshape(targetShape);\n        var normed = batchNormalization(x, broadcastMean, broadcastVariance, broadcastBeta, broadcastGamma, epsilon);\n        return [normed, mean, variance];\n    });\n}\nfunction normalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon) {\n    if (epsilon === void 0) {\n        epsilon = 1e-3;\n    }\n    if (_tfjsCore.util.arraysEqual(reductionAxes.slice().sort(), math_utils.range(0, x.rank - 1))) {\n        return regularNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon);\n    } else {\n        return broadcastNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon);\n    }\n}\nvar BatchNormalization = function (_super) {\n    __extends(BatchNormalization, _super);\n    function BatchNormalization(config) {\n        var _this = _super.call(this, config) || this;\n        _this.supportsMasking = true;\n        _this.axis = config.axis == null ? -1 : config.axis;\n        _this.momentum = config.momentum == null ? 0.99 : config.momentum;\n        _this.epsilon = config.epsilon == null ? 1e-3 : config.epsilon;\n        _this.center = config.center == null ? true : config.center;\n        _this.scale = config.scale == null ? true : config.scale;\n        _this.betaInitializer = (0, _initializers.getInitializer)(config.betaInitializer || 'zeros');\n        _this.gammaInitializer = (0, _initializers.getInitializer)(config.gammaInitializer || 'ones');\n        _this.movingMeanInitializer = (0, _initializers.getInitializer)(config.movingMeanInitializer || 'zeros');\n        _this.movingVarianceInitializer = (0, _initializers.getInitializer)(config.movingVarianceInitializer || 'ones');\n        _this.betaConstraint = (0, _constraints.getConstraint)(config.betaConstraint);\n        _this.gammaConstraint = (0, _constraints.getConstraint)(config.gammaConstraint);\n        _this.betaRegularizer = (0, _regularizers.getRegularizer)(config.betaRegularizer);\n        _this.gammaRegularizer = (0, _regularizers.getRegularizer)(config.gammaRegularizer);\n        _this.stepCount = 0;\n        return _this;\n    }\n    BatchNormalization.prototype.build = function (inputShape) {\n        inputShape = generic_utils.getExactlyOneShape(inputShape);\n        var axis = this.axis >= 0 ? this.axis : this.axis + inputShape.length;\n        var dim = inputShape[axis];\n        if (dim == null) {\n            throw new _errors.ValueError(\"Axis \" + axis + \" of input tensor should have a defined dimension but \" + \"the layer received an input with shape \" + (JSON.stringify(inputShape) + \".\"));\n        }\n        this.inputSpec = [new _topology.InputSpec({ ndim: inputShape.length, axes: (_a = {}, _a[axis] = dim, _a) })];\n        var shape = [dim];\n        if (this.scale) {\n            this.gamma = this.addWeight('gamma', shape, null, this.gammaInitializer, this.gammaRegularizer, true, this.gammaConstraint);\n        }\n        if (this.center) {\n            this.beta = this.addWeight('beta', shape, null, this.betaInitializer, this.betaRegularizer, true, this.betaConstraint);\n        }\n        this.movingMean = this.addWeight('moving_mean', shape, null, this.movingMeanInitializer, null, false);\n        this.movingVariance = this.addWeight('moving_variance', shape, null, this.movingVarianceInitializer, null, false);\n        this.built = true;\n        var _a;\n    };\n    BatchNormalization.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        return (0, _tfjsCore.tidy)(function () {\n            var training = kwargs['training'] == null ? false : kwargs['training'];\n            var input = generic_utils.getExactlyOneTensor(inputs);\n            var inputShape = K.shape(input);\n            var ndim = inputShape.length;\n            var reductionAxes = math_utils.range(0, ndim);\n            var axis = _this.axis >= 0 ? _this.axis : _this.axis + ndim;\n            reductionAxes.splice(axis, 1);\n            var broadcastShape = generic_utils.pyListRepeat(1, ndim);\n            broadcastShape[axis] = inputShape[axis];\n            var sortedReductionAxes = reductionAxes.slice();\n            sortedReductionAxes.sort();\n            var needsBroadcasting = !_tfjsCore.util.arraysEqual(sortedReductionAxes, math_utils.range(0, ndim).slice(0, ndim - 1));\n            var normalizeInference = function () {\n                if (needsBroadcasting) {\n                    var broadcastMovingMean = _this.movingMean.read().reshape(broadcastShape);\n                    var broadcastMovingVariance = _this.movingVariance.read().reshape(broadcastShape);\n                    var broadcastBeta = _this.center ? _this.beta.read().reshape(broadcastShape) : null;\n                    var broadcastGamma = _this.scale ? _this.gamma.read().reshape(broadcastShape) : null;\n                    return batchNormalization(input, broadcastMovingMean, broadcastMovingVariance, broadcastBeta, broadcastGamma, _this.epsilon);\n                } else {\n                    return batchNormalization(input, _this.movingMean.read(), _this.movingVariance.read(), _this.beta == null ? null : _this.beta.read(), _this.gamma == null ? null : _this.gamma.read(), _this.epsilon);\n                }\n            };\n            if (!training) {\n                return normalizeInference();\n            }\n            var _a = normalizeBatchInTraining(input, _this.gamma.read(), _this.beta.read(), reductionAxes, _this.epsilon),\n                normedTraining = _a[0],\n                mean = _a[1],\n                variance = _a[2];\n            var sampleSize = math_utils.arrayProd(reductionAxes.map(function (axis) {\n                return input.shape[axis];\n            }));\n            var varianceDebiased = variance.mul(K.getScalar(sampleSize / (sampleSize - (1 + _this.epsilon))));\n            var updateMovingMeanAndVariance = function () {\n                _this.stepCount++;\n                var newMovingMean = tfc.movingAverage(_this.movingMean.read(), mean, _this.momentum, _this.stepCount);\n                _this.movingMean.write(newMovingMean);\n                var newMovingVariance = tfc.movingAverage(_this.movingVariance.read(), varianceDebiased, _this.momentum, _this.stepCount);\n                _this.movingVariance.write(newMovingVariance);\n            };\n            updateMovingMeanAndVariance();\n            return normedTraining;\n        });\n    };\n    BatchNormalization.prototype.getConfig = function () {\n        var config = {\n            axis: this.axis,\n            momentum: this.momentum,\n            epsilon: this.epsilon,\n            center: this.center,\n            scale: this.scale,\n            betaInitializer: (0, _initializers.serializeInitializer)(this.betaInitializer),\n            gammaInitializer: (0, _initializers.serializeInitializer)(this.gammaInitializer),\n            movingMeanInitializer: (0, _initializers.serializeInitializer)(this.movingMeanInitializer),\n            movingVarianceInitializer: (0, _initializers.serializeInitializer)(this.movingVarianceInitializer),\n            betaRegularizer: (0, _regularizers.serializeRegularizer)(this.betaRegularizer),\n            gammaRegularizer: (0, _regularizers.serializeRegularizer)(this.gammaRegularizer),\n            betaConstraint: (0, _constraints.serializeConstraint)(this.betaConstraint),\n            gammaConstraint: (0, _constraints.serializeConstraint)(this.gammaConstraint)\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    BatchNormalization.className = 'BatchNormalization';\n    return BatchNormalization;\n}(_topology.Layer);\nexports.BatchNormalization = BatchNormalization;\n\n_tfjsCore.serialization.SerializationMap.register(BatchNormalization);\n//# sourceMappingURL=normalization.js.map"},"hash":"426996a138b9bcabac4e451866cda806","cacheData":{"env":{}}}