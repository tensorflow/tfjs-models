{"dependencies":[{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/package.json","includedInParent":true,"mtime":1533242702575},{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/.babelrc","includedInParent":true,"mtime":1533242702523},{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":1533242740549},{"name":"../errors","loc":{"line":1,"column":27}},{"name":"./topology","loc":{"line":2,"column":27}}],"generated":{"js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\nexports.FeedDict = undefined;\nexports.execute = execute;\n\nvar _errors = require('../errors');\n\nvar _topology = require('./topology');\n\nfunction assertFeedCompatibility(key, val) {\n    if (key.dtype != null && key.dtype !== val.dtype) {\n        throw new _errors.ValueError(\"The dtype of the feed (\" + val.dtype + \") is incompatible with that of \" + (\"the key '\" + key.name + \"' (\" + key.dtype + \").\"));\n    }\n    if (key.shape != null) {\n        if (key.shape.length !== val.shape.length) {\n            throw new _errors.ValueError(\"The rank of feed (\" + val.shape.length + \") does not match the rank of \" + (\"the key (\" + key.shape.length + \").\"));\n        }\n        for (var i = 0; i < key.shape.length; ++i) {\n            if (key.shape[i] != null && key.shape[i] !== val.shape[i]) {\n                throw new _errors.ValueError(\"The \" + i + \"-th dimension of the feed (\" + val.shape[i] + \") is \" + (\"incompatible with that of the key (\" + key.shape[i] + \").\"));\n            }\n        }\n    }\n}\nvar FeedDict = function () {\n    function FeedDict(feeds) {\n        this.id2Value = {};\n        if (feeds instanceof FeedDict) {\n            for (var id in feeds.id2Value) {\n                this.id2Value[id] = feeds.id2Value[id];\n            }\n        } else {\n            if (feeds == null) {\n                return;\n            }\n            for (var _i = 0, feeds_1 = feeds; _i < feeds_1.length; _i++) {\n                var feed = feeds_1[_i];\n                this.add(feed.key, feed.value);\n            }\n        }\n    }\n    FeedDict.prototype.add = function (key, value) {\n        assertFeedCompatibility(key, value);\n        if (this.id2Value[key.id] == null) {\n            this.id2Value[key.id] = value;\n        } else {\n            throw new _errors.ValueError(\"Duplicate key: name=\" + key.name + \", id=\" + key.id);\n        }\n        return this;\n    };\n    FeedDict.prototype.addFeed = function (feed) {\n        this.add(feed.key, feed.value);\n    };\n    FeedDict.prototype.hasKey = function (key) {\n        return this.id2Value[key.id] != null;\n    };\n    FeedDict.prototype.getValue = function (key) {\n        if (this.id2Value[key.id] == null) {\n            throw new _errors.ValueError(\"Nonexistent key: \" + JSON.stringify(key));\n        } else {\n            return this.id2Value[key.id];\n        }\n    };\n    return FeedDict;\n}();\nexports.FeedDict = FeedDict;\nfunction execute(fetches, feedDict, kwargs) {\n    var arrayFetches = Array.isArray(fetches);\n    var fetchArray = arrayFetches ? fetches : [fetches];\n    var outputs = [];\n    var internalFeedDict = new FeedDict(feedDict);\n    for (var _i = 0, fetchArray_1 = fetchArray; _i < fetchArray_1.length; _i++) {\n        var fetch_1 = fetchArray_1[_i];\n        outputs.push(executeInternal(fetch_1, internalFeedDict, kwargs));\n    }\n    return arrayFetches ? outputs : outputs[0];\n}\nfunction executeInternal(fetch, internalFeedDict, kwargs) {\n    if (internalFeedDict.hasKey(fetch)) {\n        return internalFeedDict.getValue(fetch);\n    }\n    if (fetch.sourceLayer instanceof _topology.InputLayer) {\n        throw new _errors.ValueError(\"Missing a feed value for SymbolicTensor from InputLayer \" + (\"'\" + _topology.InputLayer.name + \"'\"));\n    }\n    var inputs = fetch.inputs;\n    var inputValues = [];\n    for (var _i = 0, inputs_1 = inputs; _i < inputs_1.length; _i++) {\n        var input = inputs_1[_i];\n        var inputVal = executeInternal(input, internalFeedDict, kwargs);\n        inputValues.push(inputVal);\n    }\n    var output = fetch.sourceLayer.apply(inputValues, kwargs);\n    if (!Array.isArray(output)) {\n        output = [output];\n    }\n    var layerOutputs = getNodeOutputs(fetch);\n    var outputSymbolicTensors = Array.isArray(layerOutputs) ? layerOutputs : [layerOutputs];\n    for (var i = 0; i < outputSymbolicTensors.length; ++i) {\n        internalFeedDict.add(outputSymbolicTensors[i], output[i]);\n    }\n    return output.length === 1 ? output[0] : output[fetch.outputTensorIndex];\n}\nfunction getNodeOutputs(fetch) {\n    var layerOutputs;\n    if (fetch.sourceLayer.inboundNodes.length === 1) {\n        layerOutputs = fetch.sourceLayer.output;\n    } else {\n        var nodeIndex = null;\n        for (var i = 0; i < fetch.sourceLayer.inboundNodes.length; ++i) {\n            for (var _i = 0, _a = fetch.sourceLayer.inboundNodes[i].outputTensors; _i < _a.length; _i++) {\n                var outputTensor = _a[_i];\n                if (outputTensor.id === fetch.id) {\n                    nodeIndex = i;\n                    break;\n                }\n            }\n        }\n        layerOutputs = fetch.sourceLayer.getOutputAt(nodeIndex);\n    }\n    return layerOutputs;\n}\n//# sourceMappingURL=executor.js.map"},"hash":"5c9ddf91488c453c3722799800c65b91","cacheData":{"env":{}}}