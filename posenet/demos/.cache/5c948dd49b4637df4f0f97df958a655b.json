{"dependencies":[{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/.babelrc","includedInParent":true,"mtime":1533242702523},{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/package.json","includedInParent":true,"mtime":1533242702575},{"name":"@tensorflow/tfjs","loc":{"line":17,"column":20}},{"name":"@tensorflow-models/posenet","loc":{"line":18,"column":25}}],"generated":{"js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.drawPoint = drawPoint;\nexports.drawSegment = drawSegment;\nexports.drawSkeleton = drawSkeleton;\nexports.drawKeypoints = drawKeypoints;\nexports.drawBoundingBox = drawBoundingBox;\nexports.renderToCanvas = renderToCanvas;\nexports.renderImageToCanvas = renderImageToCanvas;\nexports.drawHeatMapValues = drawHeatMapValues;\nexports.drawOffsetVectors = drawOffsetVectors;\n\nvar _tfjs = require('@tensorflow/tfjs');\n\nvar tf = _interopRequireWildcard(_tfjs);\n\nvar _posenet = require('@tensorflow-models/posenet');\n\nvar posenet = _interopRequireWildcard(_posenet);\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nlet color;\nlet i = 0;\nfunction change() {\n  let colorArr = ['red', 'orange', 'yellow', 'green', 'blue', 'purple'];\n  color = colorArr[i];\n  i = (i + 1) % color.length;\n}\nsetInterval(change, 1000);\n\n// const color = 'turquoise';\nconst lineWidth = 2;\n\nfunction toTuple({ y, x }) {\n  return [y, x];\n}\n\nfunction drawPoint(ctx, y, x, r, color) {\n  ctx.beginPath();\n  ctx.arc(x, y, r, 0, 2 * Math.PI);\n  for (let i = 0; i < 6; i++) {\n    for (let j = 0; j < 6; j++) {\n      ctx.fillStyle = 'rgb(' + Math.floor(255 - 42.5 * i) + ', ' + Math.floor(255 - 42.5 * j) + ', 0)';\n    }\n  }\n  ctx.fill();\n}\n\n/**\n * Draws a line on a canvas, i.e. a joint\n */\nfunction drawSegment([ay, ax], [by, bx], color, scale, ctx) {\n  ctx.beginPath();\n  ctx.moveTo(ax * scale, ay * scale);\n  ctx.lineTo(bx * scale, by * scale);\n  ctx.lineWidth = lineWidth;\n  ctx.strokeStyle = color;\n  ctx.stroke();\n}\n\n/**\n * Draws a pose skeleton by looking up all adjacent keypoints/joints\n */\nfunction drawSkeleton(keypoints, minConfidence, ctx, scale = 1) {\n  const adjacentKeyPoints = posenet.getAdjacentKeyPoints(keypoints, minConfidence);\n\n  adjacentKeyPoints.forEach(keypoints => {\n    drawSegment(toTuple(keypoints[0].position), toTuple(keypoints[1].position), color, scale, ctx);\n  });\n}\n\n/**\n * Draw pose keypoints onto a canvas\n */\nfunction drawKeypoints(keypoints, minConfidence, ctx, scale = 1) {\n  for (let i = 0; i < keypoints.length; i++) {\n    const keypoint = keypoints[i];\n\n    if (keypoint.score < minConfidence) {\n      continue;\n    }\n\n    const { y, x } = keypoint.position;\n    drawPoint(ctx, y * scale, x * scale, 3, color);\n  }\n}\n\n/**\n * Draw the bounding box of a pose. For example, for a whole person standing\n * in an image, the bounding box will begin at the nose and extend to one of\n * ankles\n */\nfunction drawBoundingBox(keypoints, ctx) {\n  const boundingBox = posenet.getBoundingBox(keypoints);\n\n  ctx.rect(boundingBox.minX, boundingBox.minY, boundingBox.maxX - boundingBox.minX, boundingBox.maxY - boundingBox.minY);\n\n  ctx.stroke();\n}\n\n/**\n * Converts an arary of pixel data into an ImageData object\n */\nasync function renderToCanvas(a, ctx) {\n  const [height, width] = a.shape;\n  const imageData = new ImageData(width, height);\n\n  const data = await a.data();\n\n  for (let i = 0; i < height * width; ++i) {\n    const j = i * 4;\n    const k = i * 3;\n\n    imageData.data[j + 0] = data[k + 0];\n    imageData.data[j + 1] = data[k + 1];\n    imageData.data[j + 2] = data[k + 2];\n    imageData.data[j + 3] = 255;\n  }\n\n  ctx.putImageData(imageData, 0, 0);\n}\n\n/**\n * Draw an image on a canvas\n */\nfunction renderImageToCanvas(image, size, canvas) {\n  canvas.width = size[0];\n  canvas.height = size[1];\n  const ctx = canvas.getContext('2d');\n\n  ctx.drawImage(image, 0, 0);\n}\n\n/**\n * Draw heatmap values, one of the model outputs, on to the canvas\n * Read our blog post for a description of PoseNet's heatmap outputs\n * https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5\n */\nfunction drawHeatMapValues(heatMapValues, outputStride, canvas) {\n  const ctx = canvas.getContext('2d');\n  const radius = 5;\n  const scaledValues = heatMapValues.mul(tf.scalar(outputStride, 'int32'));\n\n  drawPoints(ctx, scaledValues, radius, color);\n}\n\n/**\n * Used by the drawHeatMapValues method to draw heatmap points on to\n * the canvas\n */\nfunction drawPoints(ctx, points, radius, color) {\n  const data = points.buffer().values;\n\n  for (let i = 0; i < data.length; i += 2) {\n    const pointY = data[i];\n    const pointX = data[i + 1];\n\n    if (pointX !== 0 && pointY !== 0) {\n      ctx.beginPath();\n      ctx.arc(pointX, pointY, radius, 0, 2 * Math.PI);\n      for (let i = 0; i < 6; i++) {\n        for (let j = 0; j < 6; j++) {\n          ctx.fillStyle = 'rgb(' + Math.floor(255 - 42.5 * i) + ', ' + Math.floor(255 - 42.5 * j) + ', 0)';\n        }\n      }\n      ctx.fill();\n    }\n  }\n}\n\n/**\n * Draw offset vector values, one of the model outputs, on to the canvas\n * Read our blog post for a description of PoseNet's offset vector outputs\n * https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5\n */\nfunction drawOffsetVectors(heatMapValues, offsets, outputStride, scale = 1, ctx) {\n  const offsetPoints = posenet.singlePose.getOffsetPoints(heatMapValues, outputStride, offsets);\n\n  const heatmapData = heatMapValues.buffer().values;\n  const offsetPointsData = offsetPoints.buffer().values;\n\n  for (let i = 0; i < heatmapData.length; i += 2) {\n    const heatmapY = heatmapData[i] * outputStride;\n    const heatmapX = heatmapData[i + 1] * outputStride;\n    const offsetPointY = offsetPointsData[i];\n    const offsetPointX = offsetPointsData[i + 1];\n\n    drawSegment([heatmapY, heatmapX], [offsetPointY, offsetPointX], color, scale, ctx);\n  }\n}"},"hash":"206e59c96ed70a15e28ebe66912e0f73","cacheData":{"env":{}}}