{"dependencies":[{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/package.json","includedInParent":true,"mtime":1533242702575},{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/.babelrc","includedInParent":true,"mtime":1533242702523},{"name":"/Users/Shoshana/Documents/Active/2018/Coding_Bootcamp/SeniorPhase/tfjs-models/posenet/demos/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":1533242740549},{"name":"@tensorflow/tfjs-core","loc":{"line":17,"column":55}},{"name":"../backend/tfjs_backend","loc":{"line":18,"column":19}},{"name":"../errors","loc":{"line":19,"column":78}},{"name":"../layers/serialization","loc":{"line":20,"column":48}},{"name":"../types","loc":{"line":21,"column":31}},{"name":"../utils/generic_utils","loc":{"line":22,"column":31}},{"name":"../utils/serialization_utils","loc":{"line":23,"column":36}},{"name":"../variables","loc":{"line":24,"column":60}},{"name":"../version","loc":{"line":25,"column":41}}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\nexports.Container = exports.InputLayer = exports.Layer = exports.Node = exports.InputSpec = undefined;\nexports.Input = Input;\nexports.getSourceInputs = getSourceInputs;\nexports.loadWeightsFromNamedTensorMap = loadWeightsFromNamedTensorMap;\nexports.loadWeightsFromJson = loadWeightsFromJson;\n\nvar _tfjsCore = require(\"@tensorflow/tfjs-core\");\n\nvar _tfjs_backend = require(\"../backend/tfjs_backend\");\n\nvar K = _interopRequireWildcard(_tfjs_backend);\n\nvar _errors = require(\"../errors\");\n\nvar _serialization = require(\"../layers/serialization\");\n\nvar _types = require(\"../types\");\n\nvar _generic_utils = require(\"../utils/generic_utils\");\n\nvar generic_utils = _interopRequireWildcard(_generic_utils);\n\nvar _serialization_utils = require(\"../utils/serialization_utils\");\n\nvar _variables = require(\"../variables\");\n\nvar _version = require(\"../version\");\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\nvar __extends = undefined && undefined.__extends || function () {\n    var extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function (d, b) {\n        d.__proto__ = b;\n    } || function (d, b) {\n        for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() {\n            this.constructor = d;\n        }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n}();\nvar __decorate = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n    var c = arguments.length,\n        r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n        d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\n\nvar InputSpec = function () {\n    function InputSpec(config) {\n        this.dtype = config.dtype;\n        this.shape = config.shape;\n        if (config.shape != null) {\n            this.ndim = config.shape.length;\n        } else {\n            this.ndim = config.ndim;\n        }\n        this.maxNDim = config.maxNDim;\n        this.minNDim = config.minNDim;\n        this.axes = config.axes || {};\n    }\n    return InputSpec;\n}();\nexports.InputSpec = InputSpec;\n\nvar _nextNodeID = 0;\nvar Node = function () {\n    function Node(config, callArgs) {\n        this.callArgs = callArgs;\n        this.id = _nextNodeID++;\n        this.outboundLayer = config.outboundLayer;\n        this.inboundLayers = config.inboundLayers;\n        this.nodeIndices = config.nodeIndices;\n        this.tensorIndices = config.tensorIndices;\n        this.inputTensors = config.inputTensors;\n        this.outputTensors = config.outputTensors;\n        this.inputMasks = config.inputMasks;\n        this.outputMasks = config.outputMasks;\n        this.inputShapes = config.inputShapes;\n        this.outputShapes = config.outputShapes;\n        for (var _i = 0, _a = config.inboundLayers; _i < _a.length; _i++) {\n            var layer = _a[_i];\n            if (layer != null) {\n                layer.outboundNodes.push(this);\n            }\n        }\n        config.outboundLayer.inboundNodes.push(this);\n    }\n    Node.prototype.getConfig = function () {\n        var inboundNames = [];\n        for (var _i = 0, _a = this.inboundLayers; _i < _a.length; _i++) {\n            var layer = _a[_i];\n            if (layer != null) {\n                inboundNames.push(layer.name);\n            } else {\n                inboundNames.push(null);\n            }\n        }\n        return {\n            outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,\n            inboundLayers: inboundNames,\n            nodeIndices: this.nodeIndices,\n            tensorIndices: this.tensorIndices\n        };\n    };\n    return Node;\n}();\nexports.Node = Node;\n\nvar _nextLayerID = 0;\nvar Layer = function (_super) {\n    __extends(Layer, _super);\n    function Layer(config) {\n        var _this = _super.call(this) || this;\n        _this._callHook = null;\n        _this._addedWeightNames = [];\n        _this._stateful = false;\n        _this.id = _nextLayerID++;\n        _this.activityRegularizer = null;\n        _this.inputSpec = null;\n        _this.supportsMasking = false;\n        _this._trainableWeights = [];\n        _this._nonTrainableWeights = [];\n        _this._losses = [];\n        _this._updates = [];\n        _this._built = false;\n        _this.inboundNodes = [];\n        _this.outboundNodes = [];\n        var name = config.name;\n        if (!name) {\n            var prefix = _this.getClassName();\n            name = generic_utils.toSnakeCase(prefix) + '_' + K.getUid(prefix);\n        }\n        _this.name = name;\n        _this.trainable = config.trainable == null ? true : config.trainable;\n        _this.updatable = config.updatable == null ? true : config.updatable;\n        if (config.inputShape != null || config.batchInputShape != null) {\n            var batchInputShape = void 0;\n            if (config.batchInputShape != null) {\n                batchInputShape = config.batchInputShape;\n            } else if (config.inputShape != null) {\n                var batchSize = null;\n                if (config.batchSize != null) {\n                    batchSize = config.batchSize;\n                }\n                batchInputShape = [batchSize].concat(config.inputShape);\n            }\n            _this.batchInputShape = batchInputShape;\n            var dtype = config.dtype;\n            if (dtype == null) {\n                dtype = config.inputDType;\n            }\n            if (dtype == null) {\n                dtype = K.floatx();\n            }\n            _this.dtype = dtype;\n        }\n        if (config.weights != null) {\n            _this.initialWeights = config.weights;\n        } else {\n            _this.initialWeights = null;\n        }\n        return _this;\n    }\n    Layer.nodeKey = function (layer, nodeIndex) {\n        return layer.name + '_ib-' + nodeIndex.toString();\n    };\n    Layer.prototype.getNodeAtIndex = function (nodeIndex, attrName) {\n        if (this.inboundNodes.length === 0) {\n            throw new _errors.RuntimeError('The layer has never been called ' + (\"and thus has no defined \" + attrName + \".\"));\n        }\n        if (this.inboundNodes.length <= nodeIndex) {\n            throw new _errors.ValueError(\"Asked to get \" + attrName + \" at node \" + nodeIndex + \", \" + (\"but the layer has only \" + this.inboundNodes.length + \" inbound nodes.\"));\n        }\n        return this.inboundNodes[nodeIndex];\n    };\n    Layer.prototype.getInputAt = function (nodeIndex) {\n        return generic_utils.singletonOrArray(this.getNodeAtIndex(nodeIndex, 'input').inputTensors);\n    };\n    Layer.prototype.getOutputAt = function (nodeIndex) {\n        return generic_utils.singletonOrArray(this.getNodeAtIndex(nodeIndex, 'output').outputTensors);\n    };\n    Object.defineProperty(Layer.prototype, \"input\", {\n        get: function () {\n            if (this.inboundNodes.length > 1) {\n                throw new _errors.AttributeError(\"Layer \" + this.name + ' has multiple inbound nodes, ' + 'hence the notion of \"layer input\" ' + 'is ill-defined. ' + 'Use `getInputAt(nodeIndex)` instead.');\n            } else if (this.inboundNodes.length === 0) {\n                throw new _errors.AttributeError(\"Layer \" + this.name + ' is not connected, no input to return.');\n            }\n            return generic_utils.singletonOrArray(this.getNodeAtIndex(0, 'input').inputTensors);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"output\", {\n        get: function () {\n            if (this.inboundNodes.length === 0) {\n                throw new _errors.AttributeError(\"Layer \" + this.name + ' has no inbound nodes.');\n            }\n            if (this.inboundNodes.length > 1) {\n                throw new _errors.AttributeError(\"Layer \" + this.name + ' has multiple inbound nodes, ' + 'hence the notion of \"layer output\" ' + 'is ill-defined. ' + 'Use `getOutputAt(nodeIndex)` instead.');\n            }\n            return generic_utils.singletonOrArray(this.getNodeAtIndex(0, 'output').outputTensors);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"losses\", {\n        get: function () {\n            return this._losses;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Layer.prototype.calculateLosses = function () {\n        return this.losses.map(function (lossFn) {\n            return lossFn();\n        });\n    };\n    Object.defineProperty(Layer.prototype, \"updates\", {\n        get: function () {\n            return this._updates;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"built\", {\n        get: function () {\n            return this._built;\n        },\n        set: function (built) {\n            this._built = built;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"trainableWeights\", {\n        get: function () {\n            if (this.trainable) {\n                return this._trainableWeights;\n            } else {\n                return [];\n            }\n        },\n        set: function (weights) {\n            this._trainableWeights = weights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"nonTrainableWeights\", {\n        get: function () {\n            if (!this.trainable) {\n                return this._trainableWeights.concat(this._nonTrainableWeights);\n            } else {\n                return this._nonTrainableWeights;\n            }\n        },\n        set: function (weights) {\n            this._nonTrainableWeights = weights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"weights\", {\n        get: function () {\n            return this.trainableWeights.concat(this.nonTrainableWeights);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"stateful\", {\n        get: function () {\n            return this._stateful;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Layer.prototype.assertInputCompatibility = function (inputs) {\n        inputs = generic_utils.toList(inputs);\n        if (this.inputSpec == null || this.inputSpec.length === 0) {\n            return;\n        }\n        var inputSpec = generic_utils.toList(this.inputSpec);\n        if (inputs.length !== inputSpec.length) {\n            throw new _errors.ValueError(\"Layer \" + this.name + \" expects \" + inputSpec.length + \" inputs, \" + (\"but it received \" + inputs.length + \" input tensors. \") + (\"Input received: \" + inputs));\n        }\n        for (var inputIndex = 0; inputIndex < inputs.length; inputIndex++) {\n            var x = inputs[inputIndex];\n            var spec = inputSpec[inputIndex];\n            if (spec == null) {\n                continue;\n            }\n            var ndim = x.rank;\n            if (spec.ndim != null) {\n                if (ndim !== spec.ndim) {\n                    throw new _errors.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" + this.name + \": \" + (\"expected ndim=\" + spec.ndim + \", found ndim=\" + ndim));\n                }\n            }\n            if (spec.maxNDim != null) {\n                if (ndim > spec.maxNDim) {\n                    throw new _errors.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" + this.name + (\": expected max_ndim=\" + spec.maxNDim + \", found ndim=\" + ndim));\n                }\n            }\n            if (spec.minNDim != null) {\n                if (ndim < spec.minNDim) {\n                    throw new _errors.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" + this.name + (\": expected min_ndim=\" + spec.minNDim + \", found ndim=\" + ndim + \".\"));\n                }\n            }\n            if (spec.dtype != null) {\n                if (K.dtype(x) !== spec.dtype) {\n                    var xDType = K.dtype(x);\n                    throw new _errors.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" + this.name + \" \" + (\": expected dtype=\" + spec.dtype + \", found dtype=\" + xDType + \".\"));\n                }\n            }\n            if (spec.axes) {\n                var xShape = K.intShape(x);\n                for (var key in spec.axes) {\n                    var axis = Number(key);\n                    var value = spec.axes[key];\n                    var xShapeAtAxis = axis >= 0 ? xShape[axis] : xShape[xShape.length + axis];\n                    if (value != null && [value, null].indexOf(xShapeAtAxis) === -1) {\n                        throw new _errors.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" + (this.name + \": expected axis \" + axis + \" of input shape to \") + (\"have value \" + value + \" but got shape \" + xShape + \".\"));\n                    }\n                }\n            }\n            if (spec.shape != null) {\n                var xShape = K.intShape(x);\n                for (var i = 0; i < spec.shape.length; ++i) {\n                    var specDim = spec.shape[i];\n                    var dim = xShape[i];\n                    if (specDim != null && dim != null) {\n                        if (specDim !== dim) {\n                            throw new _errors.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" + (this.name + \": expected shape=\" + spec.shape + \", \") + 'found shape=${xShape}.');\n                        }\n                    }\n                }\n            }\n        }\n    };\n    Layer.prototype.call = function (inputs, kwargs) {\n        return inputs;\n    };\n    Layer.prototype.invokeCallHook = function (inputs, kwargs) {\n        if (this._callHook != null) {\n            this._callHook(inputs, kwargs);\n        }\n    };\n    Layer.prototype.setCallHook = function (callHook) {\n        this._callHook = callHook;\n    };\n    Layer.prototype.clearCallHook = function () {\n        this._callHook = null;\n    };\n    Layer.prototype.apply = function (inputs, kwargs) {\n        var _this = this;\n        kwargs = kwargs || {};\n        var inputsList = generic_utils.toList(inputs);\n        var allAreSymbolic = true;\n        for (var _i = 0, inputsList_1 = inputsList; _i < inputsList_1.length; _i++) {\n            var input = inputsList_1[_i];\n            if (!(input instanceof _types.SymbolicTensor)) {\n                allAreSymbolic = false;\n                break;\n            }\n        }\n        var noneAreSymbolic = true;\n        for (var _a = 0, inputsList_2 = inputsList; _a < inputsList_2.length; _a++) {\n            var input = inputsList_2[_a];\n            if (input instanceof _types.SymbolicTensor) {\n                noneAreSymbolic = false;\n                break;\n            }\n        }\n        if (allAreSymbolic === noneAreSymbolic) {\n            throw new _errors.ValueError('Arguments to apply() must be all ' + 'SymbolicTensors or all Tensors');\n        }\n        return K.nameScope(this.name, function () {\n            if (!_this.built) {\n                _this.assertInputCompatibility(inputs);\n                var inputShapes = [];\n                for (var _i = 0, _a = generic_utils.toList(inputs); _i < _a.length; _i++) {\n                    var xElem = _a[_i];\n                    inputShapes.push(K.intShape(xElem));\n                }\n                _this.build(generic_utils.singletonOrArray(inputShapes));\n                _this.built = true;\n                if (_this.initialWeights) {\n                    _this.setWeights(_this.initialWeights);\n                }\n            }\n            _this.assertInputCompatibility(inputs);\n            if (noneAreSymbolic) {\n                var output = _this.call(inputs, kwargs);\n                var outputList = generic_utils.toList(output);\n                var outputListCopy = [];\n                for (var _b = 0, outputList_1 = outputList; _b < outputList_1.length; _b++) {\n                    var x = outputList_1[_b];\n                    if (inputsList.indexOf(x) !== -1) {\n                        x = K.identity(x);\n                    }\n                    outputListCopy.push(x);\n                }\n                output = generic_utils.singletonOrArray(outputListCopy);\n                if (_this.activityRegularizer != null) {\n                    throw new _errors.NotImplementedError('Layer invocation in the presence of activity ' + 'regularizer(s) is not supported yet.');\n                }\n                return output;\n            } else {\n                var inputShape = collectInputShape(inputs);\n                var outputShape = _this.computeOutputShape(inputShape);\n                var output = void 0;\n                var outputDType_1 = guessOutputDType(inputs);\n                if (outputShape != null && outputShape.length > 0 && Array.isArray(outputShape[0])) {\n                    output = outputShape.map(function (shape, index) {\n                        return new _types.SymbolicTensor(outputDType_1, shape, _this, generic_utils.toList(inputs), kwargs, _this.name, index);\n                    });\n                } else {\n                    output = new _types.SymbolicTensor(outputDType_1, outputShape, _this, generic_utils.toList(inputs), kwargs, _this.name);\n                }\n                _this.addInboundNode(inputs, output, null, null, inputShape, outputShape, kwargs);\n                if (_this.activityRegularizer != null) {\n                    throw new _errors.NotImplementedError('Layer invocation in the presence of activity ' + 'regularizer(s) is not supported yet.');\n                }\n                return output;\n            }\n        });\n    };\n    Layer.prototype.build = function (inputShape) {\n        this.built = true;\n    };\n    Layer.prototype.getWeights = function (trainableOnly) {\n        if (trainableOnly === void 0) {\n            trainableOnly = false;\n        }\n        return (0, _variables.batchGetValue)(trainableOnly ? this.trainableWeights : this.weights);\n    };\n    Layer.prototype.setWeights = function (weights) {\n        var _this = this;\n        (0, _tfjsCore.tidy)(function () {\n            var params = _this.weights;\n            if (params.length !== weights.length) {\n                throw new _errors.ValueError(\"You called setWeights(weights) on layer \\\"\" + _this.name + \"\\\" \" + (\"with a weight list of length \" + weights.length + \", \") + (\"but the layer was expecting \" + params.length + \" weights. \") + (\"Provided weights: \" + weights + \"...\"));\n            }\n            if (params.length === 0) {\n                return;\n            }\n            var weightValueTuples = [];\n            var paramValues = (0, _variables.batchGetValue)(params);\n            for (var i = 0; i < paramValues.length; ++i) {\n                var pv = paramValues[i];\n                var p = params[i];\n                var w = weights[i];\n                if (!_tfjsCore.util.arraysEqual(pv.shape, w.shape)) {\n                    throw new _errors.ValueError(\"Layer weight shape \" + pv.shape + \" \" + (\"not compatible with provided weight shape \" + w.shape));\n                }\n                weightValueTuples.push([p, w]);\n            }\n            (0, _variables.batchSetValue)(weightValueTuples);\n        });\n    };\n    Layer.prototype.addWeight = function (name, shape, dtype, initializer, regularizer, trainable, constraint) {\n        if (this._addedWeightNames.indexOf(name) !== -1) {\n            throw new _errors.ValueError(\"Duplicate weight name \" + name + \" for layer \" + this.name);\n        }\n        this._addedWeightNames.push(name);\n        if (dtype == null) {\n            dtype = K.floatx();\n        }\n        var weight = new _variables.LayerVariable(initializer.apply(shape, dtype), dtype, name, trainable, constraint);\n        if (regularizer != null) {\n            this.addLoss(function () {\n                return regularizer.apply(weight.read());\n            });\n        }\n        if (trainable == null) {\n            trainable = true;\n        }\n        if (trainable) {\n            this._trainableWeights.push(weight);\n        } else {\n            this._nonTrainableWeights.push(weight);\n        }\n        return weight;\n    };\n    Layer.prototype.addLoss = function (losses) {\n        if (losses == null || Array.isArray(losses) && losses.length === 0) {\n            return;\n        }\n        losses = generic_utils.toList(losses);\n        if (this._losses !== undefined && this._losses !== null) {\n            (_a = this.losses).push.apply(_a, losses);\n        }\n        var _a;\n    };\n    Layer.prototype.computeOutputShape = function (inputShape) {\n        return inputShape;\n    };\n    Layer.prototype.computeMask = function (inputs, mask) {\n        var _this = this;\n        if (!this.supportsMasking) {\n            if (mask != null) {\n                if (Array.isArray(mask)) {\n                    mask.forEach(function (maskElement) {\n                        if (maskElement != null) {\n                            throw new TypeError(\"Layer \" + _this.name + \" does not support masking,\" + 'but was passed an inputMask.');\n                        }\n                    });\n                } else {\n                    throw new TypeError(\"Layer \" + this.name + \" does not support masking,\" + 'but was passed an inputMask.');\n                }\n            }\n            return null;\n        }\n        return mask;\n    };\n    Layer.prototype.addInboundNode = function (inputTensors, outputTensors, inputMasks, outputMasks, inputShapes, outputShapes, kwargs) {\n        if (kwargs === void 0) {\n            kwargs = null;\n        }\n        var inputTensorList = generic_utils.toList(inputTensors);\n        outputTensors = generic_utils.toList(outputTensors);\n        inputMasks = generic_utils.toList(inputMasks);\n        outputMasks = generic_utils.toList(outputMasks);\n        inputShapes = generic_utils.normalizeShapeList(inputShapes);\n        outputShapes = generic_utils.normalizeShapeList(outputShapes);\n        var inboundLayers = [];\n        var nodeIndices = [];\n        var tensorIndices = [];\n        for (var _i = 0, inputTensorList_1 = inputTensorList; _i < inputTensorList_1.length; _i++) {\n            var x = inputTensorList_1[_i];\n            inboundLayers.push(x.sourceLayer);\n            nodeIndices.push(x.nodeIndex);\n            tensorIndices.push(x.tensorIndex);\n        }\n        new Node({\n            outboundLayer: this,\n            inboundLayers: inboundLayers,\n            nodeIndices: nodeIndices,\n            tensorIndices: tensorIndices,\n            inputTensors: inputTensorList,\n            outputTensors: outputTensors,\n            inputMasks: inputMasks,\n            outputMasks: outputMasks,\n            inputShapes: inputShapes,\n            outputShapes: outputShapes\n        }, kwargs);\n        for (var i = 0; i < outputTensors.length; i++) {\n            outputTensors[i].sourceLayer = this;\n            outputTensors[i].nodeIndex = this.inboundNodes.length - 1;\n            outputTensors[i].tensorIndex = i;\n        }\n    };\n    Layer.prototype.getConfig = function () {\n        var config = { name: this.name, trainable: this.trainable };\n        if (this.batchInputShape != null) {\n            config['batchInputShape'] = this.batchInputShape;\n        }\n        if (this.dtype != null) {\n            config['dtype'] = this.dtype;\n        }\n        return config;\n    };\n    __decorate([(0, _tfjsCore.doc)({ heading: 'Models', 'subheading': 'Classes' })], Layer.prototype, \"apply\", null);\n    Layer = __decorate([(0, _tfjsCore.doc)({ heading: 'Layers', subheading: 'Classes', namespace: 'layers' })], Layer);\n    return Layer;\n}(_tfjsCore.serialization.Serializable);\nexports.Layer = Layer;\n\nfunction collectInputShape(inputTensors) {\n    inputTensors = generic_utils.toList(inputTensors);\n    var shapes = [];\n    for (var _i = 0, inputTensors_1 = inputTensors; _i < inputTensors_1.length; _i++) {\n        var x = inputTensors_1[_i];\n        shapes.push(K.intShape(x));\n    }\n    return generic_utils.singletonOrArray(shapes);\n}\nfunction guessOutputDType(inputTensors) {\n    return 'float32';\n}\nvar InputLayer = function (_super) {\n    __extends(InputLayer, _super);\n    function InputLayer(config) {\n        var _this = _super.call(this, {\n            dtype: config.dtype,\n            name: config.name != null ? config.name : K.getUid('input').toString()\n        }) || this;\n        if (config.batchSize == null) {\n            config.batchSize = null;\n        }\n        if (config.sparse == null) {\n            config.sparse = false;\n        }\n        _this.trainable = false;\n        _this.built = true;\n        _this.sparse = config.sparse;\n        if (config.inputShape != null && config.batchInputShape != null) {\n            throw new _errors.ValueError('Only provide the inputShape OR ' + 'batchInputShape argument to inputLayer, not both at the same time.');\n        }\n        var batchInputShape = config.batchInputShape;\n        if (batchInputShape == null) {\n            if (config.inputShape == null) {\n                throw new _errors.ValueError('An InputLayer should be passed either a ' + '`batchInputShape` or an `inputShape`.');\n            } else {\n                batchInputShape = [config.batchSize].concat(config.inputShape);\n            }\n        } else {\n            if (config.batchSize != null) {\n                throw new _errors.ValueError('Cannot specify batchSize if batchInputShape is' + 'specified when creating an InputLayer.');\n            }\n        }\n        var dtype = config.dtype || K.floatx();\n        _this.batchInputShape = batchInputShape;\n        _this.dtype = dtype;\n        _this.inputSpec = [{ shape: batchInputShape }];\n        var inputTensor = new _types.SymbolicTensor(_this.dtype, _this.batchInputShape, _this, [], {}, _this.name);\n        inputTensor.nodeIndex = 0;\n        inputTensor.tensorIndex = 0;\n        new Node({\n            outboundLayer: _this,\n            inboundLayers: [],\n            nodeIndices: [],\n            tensorIndices: [],\n            inputTensors: [inputTensor],\n            outputTensors: [inputTensor],\n            inputMasks: [null],\n            outputMasks: [null],\n            inputShapes: [batchInputShape],\n            outputShapes: [batchInputShape]\n        });\n        return _this;\n    }\n    InputLayer.prototype.apply = function (inputs, kwargs) {\n        throw new _errors.ValueError('Cannot pass any input to an ' + (\"InputLayer's apply() method. InputLayer name: \" + this.name));\n    };\n    InputLayer.prototype.getConfig = function () {\n        return {\n            batchInputShape: this.batchInputShape,\n            dtype: this.dtype,\n            sparse: this.sparse,\n            name: this.name\n        };\n    };\n    InputLayer.className = 'InputLayer';\n    return InputLayer;\n}(Layer);\nexports.InputLayer = InputLayer;\n\n_tfjsCore.serialization.SerializationMap.register(InputLayer);\nfunction Input(config) {\n    if (config.batchShape == null && config.shape == null) {\n        throw new Error('Please provide to Input either a `shape`' + ' or a `batchShape` argument. Note that ' + '`shape` does not include the batch ' + 'dimension.');\n    }\n    if (config.batchShape != null && config.shape != null) {\n        throw new _errors.ValueError('Please provide either a `shape` or `batchShape` ' + 'argument to Input, but not both.');\n    }\n    var batchShape = config.batchShape;\n    if (config.shape != null && batchShape == null) {\n        batchShape = [null].concat(config.shape);\n    }\n    var dtype = config.dtype;\n    if (dtype == null) {\n        dtype = K.floatx();\n    }\n    var inputLayer = new InputLayer({\n        batchInputShape: batchShape,\n        name: config.name,\n        dtype: dtype,\n        sparse: config.sparse\n    });\n    var outputs = inputLayer.inboundNodes[0].outputTensors;\n    return outputs[0];\n}\nvar Container = function (_super) {\n    __extends(Container, _super);\n    function Container(config) {\n        var _this = _super.call(this, {}) || this;\n        _this.containerNodes = new Set();\n        _this.name = config.name;\n        if (_this.name == null) {\n            var prefix = _this.getClassName().toLowerCase();\n            _this.name = K.getUid(prefix);\n        }\n        _this.supportsMasking = false;\n        _this.trainable = true;\n        _this.updatable = true;\n        if (Array.isArray(config.inputs)) {\n            _this.inputs = config.inputs.slice();\n        } else {\n            _this.inputs = [config.inputs];\n        }\n        if (Array.isArray(config.outputs)) {\n            _this.outputs = config.outputs.slice();\n        } else {\n            _this.outputs = [config.outputs];\n        }\n        if (generic_utils.unique(_this.inputs).length !== _this.inputs.length) {\n            throw new _errors.ValueError('The list of inputs passed to the model is ' + 'redundant. All inputs should only appear once. Found: ' + _this.inputs.map(function (x) {\n                return x.name;\n            }));\n        }\n        if (generic_utils.unique(_this.outputs).length !== _this.outputs.length) {\n            console.warn('The list of outputs passed to the model is redundant. ' + 'All outputs should only appear once. Found: ' + _this.outputs.map(function (x) {\n                return x.name;\n            }));\n        }\n        _this.inputLayers = [];\n        _this.inputLayersNodeIndices = [];\n        _this.inputLayersTensorIndices = [];\n        _this.outputLayers = [];\n        _this.outputLayersNodeIndices = [];\n        _this.outputLayersTensorIndices = [];\n        _this.layers = [];\n        for (var _i = 0, _a = _this.outputs; _i < _a.length; _i++) {\n            var x = _a[_i];\n            var layer = x.sourceLayer;\n            var nodeIndex = x.nodeIndex;\n            var tensorIndex = x.tensorIndex;\n            _this.outputLayers.push(layer);\n            _this.outputLayersNodeIndices.push(nodeIndex);\n            _this.outputLayersTensorIndices.push(tensorIndex);\n        }\n        for (var _b = 0, _c = _this.inputs; _b < _c.length; _b++) {\n            var x = _c[_b];\n            var layer = x.sourceLayer;\n            var nodeIndex = x.nodeIndex;\n            var tensorIndex = x.tensorIndex;\n            generic_utils.assert(nodeIndex === 0, 'input layer has >1 nodes');\n            generic_utils.assert(tensorIndex === 0, 'input layer has >1 tensors');\n            _this.inputLayers.push(layer);\n            _this.inputLayersNodeIndices.push(nodeIndex);\n            _this.inputLayersTensorIndices.push(tensorIndex);\n        }\n        _this.inputNames = [];\n        _this.outputNames = [];\n        _this.feedInputShapes = [];\n        _this.feedInputNames = [];\n        _this.feedOutputNames = [];\n        for (var i = 0; i < _this.inputLayers.length; i++) {\n            var layer = _this.inputLayers[i];\n            if (!(layer instanceof InputLayer)) {\n                throw new TypeError('Input layers to a Model must be InputLayer objects. ' + (\"Received inputs: \" + config.inputs + \". \") + (\"Input \" + i + \" (0-based) originates \") + (\"from layer type \" + layer.getClassName() + \".\"));\n            }\n            _this.inputNames.push(layer.name);\n            _this.feedInputShapes.push(layer.batchInputShape);\n            _this.feedInputNames.push(layer.name);\n        }\n        for (var _d = 0, _e = _this.outputLayers; _d < _e.length; _d++) {\n            var layer = _e[_d];\n            _this.outputNames.push(layer.name);\n        }\n        _this.internalInputShapes = _this.inputs.map(function (x) {\n            return x.shape;\n        });\n        _this.internalOutputShapes = _this.outputs.map(function (x) {\n            return x.shape;\n        });\n        var nodesDepths = {};\n        var nodeIDToNode = {};\n        var layersDepths = {};\n        var layerIDToLayer = {};\n        var layerIndices = {};\n        var nodesInDecreasingDepth = [];\n        var buildMapOfGraph = function (tensor, finishedNodes, nodesInProgress, layer, nodeIndex, tensorIndex) {\n            if (layer == null || nodeIndex == null || tensorIndex == null) {\n                layer = tensor.sourceLayer;\n                nodeIndex = tensor.nodeIndex;\n                tensorIndex = tensor.tensorIndex;\n            }\n            var node = layer.inboundNodes[nodeIndex];\n            if (nodesInProgress.indexOf(node) !== -1) {\n                throw new _errors.RuntimeError(\"The tensor \" + tensor.name + \" at layer \\\"\" + layer.name + \"\\\" \" + 'is part of a cycle.');\n            }\n            if (finishedNodes.indexOf(node) !== -1) {\n                return;\n            }\n            _this.containerNodes.add(Container.nodeKey(layer, nodeIndex));\n            if (!(layer.id in layerIndices)) {\n                layerIndices[layer.id] = Object.keys(layerIndices).length;\n            }\n            if (nodesInProgress.indexOf(node) === -1) {\n                nodesInProgress.push(node);\n            }\n            var numInboundLayers = node.inboundLayers.length;\n            for (var i = 0; i < numInboundLayers; i++) {\n                var x = node.inputTensors[i];\n                var layer_1 = node.inboundLayers[i];\n                var nodeIndex_1 = node.nodeIndices[i];\n                var tensorIndex_1 = node.tensorIndices[i];\n                buildMapOfGraph(x, finishedNodes, nodesInProgress, layer_1, nodeIndex_1, tensorIndex_1);\n            }\n            finishedNodes.push(node);\n            while (nodesInProgress.indexOf(node) >= 0) {\n                nodesInProgress.splice(nodesInProgress.indexOf(node), 1);\n            }\n            nodesInDecreasingDepth.push(node);\n        };\n        var finishedNodes = [];\n        var nodesInProgress = [];\n        for (var _f = 0, _g = _this.outputs; _f < _g.length; _f++) {\n            var x = _g[_f];\n            buildMapOfGraph(x, finishedNodes, nodesInProgress);\n        }\n        var reversedNodesInDecreasingDepth = nodesInDecreasingDepth.slice().reverse();\n        for (var _h = 0, reversedNodesInDecreasingDepth_1 = reversedNodesInDecreasingDepth; _h < reversedNodesInDecreasingDepth_1.length; _h++) {\n            var node = reversedNodesInDecreasingDepth_1[_h];\n            nodeIDToNode[node.id] = node;\n            if (!(node.id in nodesDepths)) {\n                nodesDepths[node.id] = 0;\n            }\n            var depth = nodesDepths[node.id];\n            var previousDepth = layersDepths[node.outboundLayer.id] == null ? 0 : layersDepths[node.outboundLayer.id];\n            depth = Math.max(depth, previousDepth);\n            layersDepths[node.outboundLayer.id] = depth;\n            layerIDToLayer[node.outboundLayer.id] = node.outboundLayer;\n            nodesDepths[node.id] = depth;\n            for (var i = 0; i < node.inboundLayers.length; i++) {\n                var inboundLayer = node.inboundLayers[i];\n                var nodeIndex = node.nodeIndices[i];\n                var inboundNode = inboundLayer.inboundNodes[nodeIndex];\n                var previousDepth_1 = nodesDepths[inboundNode.id] == null ? 0 : nodesDepths[inboundNode.id];\n                nodesDepths[inboundNode.id] = Math.max(depth + 1, previousDepth_1);\n                nodeIDToNode[inboundNode.id] = inboundNode;\n            }\n        }\n        var nodesByDepth = {};\n        for (var nodeID in nodesDepths) {\n            var depth = nodesDepths[nodeID];\n            if (!(depth in nodesByDepth)) {\n                nodesByDepth[depth] = [];\n            }\n            nodesByDepth[depth].push(nodeIDToNode[nodeID]);\n        }\n        var layersByDepth = {};\n        for (var layerID in layersDepths) {\n            var depth = layersDepths[layerID];\n            if (!(depth in layersByDepth)) {\n                layersByDepth[depth] = [];\n            }\n            layersByDepth[depth].push(layerIDToLayer[layerID]);\n        }\n        var depthKeys = Object.keys(layersByDepth).map(function (x) {\n            return parseInt(x, 10);\n        }).sort(generic_utils.reverseNumberCompare);\n        _this.layers = [];\n        for (var _j = 0, depthKeys_1 = depthKeys; _j < depthKeys_1.length; _j++) {\n            var depth = depthKeys_1[_j];\n            var layersForDepth = layersByDepth[depth];\n            layersForDepth.sort(function (a, b) {\n                var aIndex = layerIndices[a.id];\n                var bIndex = layerIndices[b.id];\n                if (aIndex < bIndex) {\n                    return -1;\n                }\n                if (aIndex > bIndex) {\n                    return 1;\n                }\n                return 0;\n            });\n            for (var _k = 0, layersForDepth_1 = layersForDepth; _k < layersForDepth_1.length; _k++) {\n                var layer = layersForDepth_1[_k];\n                _this.layers.push(layer);\n            }\n        }\n        _this.layersByDepth = layersByDepth;\n        depthKeys = Object.keys(nodesByDepth).map(function (x) {\n            return parseInt(x, 10);\n        }).sort(generic_utils.reverseNumberCompare);\n        var computableTensors = _this.inputs.slice();\n        var layersWithCompleteInput = [];\n        for (var _l = 0, depthKeys_2 = depthKeys; _l < depthKeys_2.length; _l++) {\n            var depth = depthKeys_2[_l];\n            for (var _m = 0, _o = nodesByDepth[depth]; _m < _o.length; _m++) {\n                var node = _o[_m];\n                var layer = node.outboundLayer;\n                if (layer != null) {\n                    for (var _p = 0, _q = node.inputTensors; _p < _q.length; _p++) {\n                        var x = _q[_p];\n                        if (computableTensors.indexOf(x) === -1) {\n                            throw new _errors.RuntimeError(\"Graph disconnected: cannot obtain value for tensor \" + x + (\" at layer \\\"\" + layer.name + \"\\\". \") + 'The following previous layers were accessed without ' + (\"issue: \" + layersWithCompleteInput));\n                        }\n                    }\n                    for (var _r = 0, _s = node.outputTensors; _r < _s.length; _r++) {\n                        var x = _s[_r];\n                        computableTensors.push(x);\n                    }\n                    layersWithCompleteInput.push(layer.name);\n                }\n            }\n        }\n        _this.nodesByDepth = nodesByDepth;\n        var allNames = _this.layers.map(function (x) {\n            return x.name;\n        });\n        var _loop_1 = function (name_1) {\n            var numOccurrences = allNames.filter(function (x) {\n                return x === name_1;\n            }).length;\n            if (numOccurrences !== 1) {\n                throw new _errors.RuntimeError(\"The name \\\"\" + name_1 + \"\\\" is used \" + numOccurrences + \" times \" + 'in the model. All layer names should be unique. Layer names: ' + JSON.stringify(allNames));\n            }\n        };\n        for (var _t = 0, allNames_1 = allNames; _t < allNames_1.length; _t++) {\n            var name_1 = allNames_1[_t];\n            _loop_1(name_1);\n        }\n        _this.outboundNodes = [];\n        _this.inboundNodes = [];\n        new Node({\n            outboundLayer: _this,\n            inboundLayers: [],\n            nodeIndices: [],\n            tensorIndices: [],\n            inputTensors: _this.inputs,\n            outputTensors: _this.outputs,\n            inputMasks: _this.inputs.map(function (x) {\n                return null;\n            }),\n            outputMasks: _this.outputs.map(function (x) {\n                return null;\n            }),\n            inputShapes: _this.inputs.map(function (x) {\n                return x.shape;\n            }),\n            outputShapes: _this.outputs.map(function (x) {\n                return x.shape;\n            })\n        });\n        _this.built = true;\n        return _this;\n    }\n    Object.defineProperty(Container.prototype, \"trainableWeights\", {\n        get: function () {\n            if (this._trainableWeights.length > 0) {\n                throw new _errors.ValueError('Container instance unexpectedly contains _trainableWeights.' + 'The trainable weights of a Container are a union of the ' + 'trainable weights of its consituent Layers. Its own ' + '_trainableWeights must remain an empty Array.');\n            }\n            if (!this.trainable) {\n                return [];\n            }\n            var weights = [];\n            for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n                var layer = _a[_i];\n                weights = weights.concat(layer.trainableWeights);\n            }\n            return weights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Container.prototype, \"nonTrainableWeights\", {\n        get: function () {\n            var weights = [];\n            for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n                var layer = _a[_i];\n                weights.push.apply(weights, layer.nonTrainableWeights);\n            }\n            if (!this.trainable) {\n                var trainableWeights = [];\n                for (var _b = 0, _c = this.layers; _b < _c.length; _b++) {\n                    var layer = _c[_b];\n                    trainableWeights.push.apply(trainableWeights, layer.trainableWeights);\n                }\n                return trainableWeights.concat(weights);\n            }\n            return weights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Container.prototype, \"weights\", {\n        get: function () {\n            return this.trainableWeights.concat(this.nonTrainableWeights);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Container.prototype.loadWeights = function (weightsJSON, skipMismatch, isNamedTensorMap) {\n        if (skipMismatch === void 0) {\n            skipMismatch = false;\n        }\n        if (isNamedTensorMap === void 0) {\n            isNamedTensorMap = false;\n        }\n        if (isNamedTensorMap) {\n            loadWeightsFromNamedTensorMap(weightsJSON, this.layers);\n        } else {\n            loadWeightsFromJson(weightsJSON, this.layers, skipMismatch);\n        }\n    };\n    Container.prototype.updatedConfig = function () {\n        var theConfig = this.getConfig();\n        var modelConfig = {\n            className: this.getClassName(),\n            config: theConfig,\n            kerasVersion: \"tfjs-layers \" + _version.version,\n            backend: 'TensorFlow.js'\n        };\n        return modelConfig;\n    };\n    Container.prototype.toJSON = function (unused, returnString) {\n        if (returnString === void 0) {\n            returnString = true;\n        }\n        var modelConfig = (0, _serialization_utils.convertTsToPythonic)(this.updatedConfig());\n        return returnString ? JSON.stringify(modelConfig) : modelConfig;\n    };\n    Container.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        return (0, _tfjsCore.tidy)(function () {\n            inputs = generic_utils.toList(inputs);\n            var masks;\n            if ('mask' in kwargs) {\n                masks = generic_utils.toList(kwargs['mask']);\n            } else {\n                masks = generic_utils.pyListRepeat(null, inputs.length);\n            }\n            return _this.runInternalGraph(inputs, masks)[0];\n        });\n    };\n    Container.prototype.computeMask = function (inputs, mask) {\n        var _this = this;\n        return (0, _tfjsCore.tidy)(function () {\n            inputs = generic_utils.toList(inputs);\n            var masks;\n            if (mask == null) {\n                masks = generic_utils.pyListRepeat(null, inputs.length);\n            } else {\n                masks = generic_utils.toList(mask);\n            }\n            return _this.runInternalGraph(inputs, masks)[1];\n        });\n    };\n    Container.prototype.computeOutputShape = function (inputShape) {\n        var inputShapes = generic_utils.normalizeShapeList(inputShape);\n        if (inputShapes.length !== this.inputLayers.length) {\n            throw new _errors.ValueError(\"Invalid inputShape argument \" + inputShape + \": \" + (\"model has \" + this.inputLayers.length + \" tensor inputs.\"));\n        }\n        var layersToOutputShapes = {};\n        for (var i = 0; i < inputShapes.length; i++) {\n            var layer = this.inputLayers[i];\n            var inputShape_1 = inputShapes[i];\n            var shapeKey = layer.name + '_0_0';\n            layersToOutputShapes[shapeKey] = inputShape_1;\n        }\n        var depthKeys = Object.keys(this.nodesByDepth).map(function (x) {\n            return parseInt(x, 10);\n        }).sort(generic_utils.reverseNumberCompare);\n        if (depthKeys.length > 1) {\n            for (var _i = 0, depthKeys_3 = depthKeys; _i < depthKeys_3.length; _i++) {\n                var depth = depthKeys_3[_i];\n                var nodes = this.nodesByDepth[depth];\n                for (var _a = 0, nodes_1 = nodes; _a < nodes_1.length; _a++) {\n                    var node = nodes_1[_a];\n                    var layer = node.outboundLayer;\n                    if (this.inputLayers.map(function (x) {\n                        return x.id;\n                    }).indexOf(layer.id) !== -1) {\n                        continue;\n                    }\n                    var inputShapes_1 = [];\n                    for (var j = 0; j < node.inboundLayers.length; j++) {\n                        var inboundLayer = node.inboundLayers[j];\n                        var nodeIndex_2 = node.nodeIndices[j];\n                        var tensorIndex = node.tensorIndices[j];\n                        var shapeKey = inboundLayer.name + \"_\" + nodeIndex_2 + \"_\" + tensorIndex;\n                        var inputShape_2 = layersToOutputShapes[shapeKey];\n                        inputShapes_1.push(inputShape_2);\n                    }\n                    var outputShape = layer.computeOutputShape(generic_utils.singletonOrArray(inputShapes_1));\n                    var outputShapes_1 = generic_utils.normalizeShapeList(outputShape);\n                    var nodeIndex = layer.inboundNodes.indexOf(node);\n                    for (var j = 0; j < outputShapes_1.length; j++) {\n                        var shapeKey = layer.name + \"_\" + nodeIndex + \"_\" + j;\n                        layersToOutputShapes[shapeKey] = outputShapes_1[j];\n                    }\n                }\n            }\n        }\n        var outputShapes = [];\n        var outputShapeKeys = [];\n        for (var i = 0; i < this.outputLayers.length; i++) {\n            var layer = this.outputLayers[i];\n            var nodeIndex = this.outputLayersNodeIndices[i];\n            var tensorIndex = this.outputLayersTensorIndices[i];\n            var shapeKey = layer.name + \"_\" + nodeIndex + \"_\" + tensorIndex;\n            outputShapeKeys.push(shapeKey);\n        }\n        for (var i = 0; i < outputShapeKeys.length; i++) {\n            var key = outputShapeKeys[i];\n            generic_utils.assert(key in layersToOutputShapes);\n            outputShapes.push(layersToOutputShapes[key]);\n        }\n        return generic_utils.singletonOrArray(outputShapes);\n    };\n    Container.prototype.runInternalGraph = function (inputs, masks) {\n        if (masks == null) {\n            masks = generic_utils.pyListRepeat(null, inputs.length);\n        }\n        var tensorMap = {};\n        for (var i = 0; i < this.inputs.length; ++i) {\n            var x = this.inputs[i];\n            var y = inputs[i];\n            var mask = masks[i];\n            tensorMap[x.id] = [y, mask];\n        }\n        var depthKeys = Object.keys(this.nodesByDepth).map(function (x) {\n            return parseInt(x, 10);\n        }).sort(generic_utils.reverseNumberCompare);\n        for (var _i = 0, depthKeys_4 = depthKeys; _i < depthKeys_4.length; _i++) {\n            var depth = depthKeys_4[_i];\n            var nodes = this.nodesByDepth[depth];\n            for (var _a = 0, nodes_2 = nodes; _a < nodes_2.length; _a++) {\n                var node = nodes_2[_a];\n                var layer = node.outboundLayer;\n                var referenceInputTensors = node.inputTensors;\n                var referenceOutputTensors = node.outputTensors;\n                var computedData = new Array();\n                for (var _b = 0, referenceInputTensors_1 = referenceInputTensors; _b < referenceInputTensors_1.length; _b++) {\n                    var x = referenceInputTensors_1[_b];\n                    if (x.id in tensorMap) {\n                        computedData.push(tensorMap[x.id]);\n                    }\n                }\n                if (computedData.length === referenceInputTensors.length) {\n                    var kwargs = {};\n                    var computedTensors = void 0;\n                    var computedMasks = void 0;\n                    var outputTensors_1 = void 0;\n                    var outputMasks_1 = void 0;\n                    if (node.callArgs != null) {\n                        kwargs = node.callArgs;\n                    }\n                    if (computedData.length === 1) {\n                        var _c = computedData[0],\n                            computedTensor = _c[0],\n                            computedMask = _c[1];\n                        if (kwargs.mask == null) {\n                            kwargs['mask'] = computedMask;\n                        }\n                        outputTensors_1 = generic_utils.toList(layer.call(computedTensor, kwargs));\n                        outputMasks_1 = generic_utils.toList(layer.computeMask(computedTensor, computedMask));\n                        computedTensors = [computedTensor];\n                        computedMasks = [computedMask];\n                    } else {\n                        computedTensors = computedData.map(function (x) {\n                            return x[0];\n                        });\n                        computedMasks = computedData.map(function (x) {\n                            return x[1];\n                        });\n                        if (kwargs.mask == null) {\n                            kwargs['mask'] = computedMasks;\n                        }\n                        outputTensors_1 = generic_utils.toList(layer.call(computedTensors, kwargs));\n                        outputMasks_1 = generic_utils.toList(layer.computeMask(computedTensors, computedMasks));\n                    }\n                    if (layer.activityRegularizer) {\n                        throw new _errors.NotImplementedError('Model invocation with concrete Tensor value(s) in the ' + 'presence of activity regularizer(s) is not supported yet.');\n                    }\n                    for (var i = 0; i < referenceOutputTensors.length; ++i) {\n                        var x = referenceOutputTensors[i];\n                        var y = outputTensors_1[i];\n                        var mask = outputMasks_1[i];\n                        tensorMap[x.id] = [y, mask];\n                    }\n                }\n            }\n        }\n        var outputTensors = [];\n        var outputMasks = [];\n        var outputShapes = [];\n        for (var _d = 0, _e = this.outputs; _d < _e.length; _d++) {\n            var x = _e[_d];\n            generic_utils.assert(x.id in tensorMap, \"Could not compute output \" + x.name + \" : \" + x.id);\n            var _f = tensorMap[x.id],\n                tensor = _f[0],\n                mask = _f[1];\n            outputShapes.push(tensor.shape);\n            outputTensors.push(tensor);\n            outputMasks.push(mask);\n        }\n        return [outputTensors, outputMasks, outputShapes];\n    };\n    Container.prototype.buildNodeConversionMap = function (layers) {\n        var nodeConversionMap = {};\n        var keptNodes;\n        for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n            var layer = _a[_i];\n            keptNodes = layer instanceof Container ? 1 : 0;\n            for (var originalNodeIndex = 0; originalNodeIndex < layer.inboundNodes.length; originalNodeIndex++) {\n                var nodeKey = Container.nodeKey(layer, originalNodeIndex);\n                if (nodeKey in this.containerNodes) {\n                    nodeConversionMap[nodeKey] = keptNodes;\n                    keptNodes += 1;\n                }\n            }\n        }\n        return nodeConversionMap;\n    };\n    Container.prototype.getLayer = function (name, index) {\n        if (index != null) {\n            if (this.layers.length <= index) {\n                throw new _errors.ValueError(\"Was asked to retrieve layer at index \" + index + \", but model only \" + (\"has \" + this.layers.length + \" layer(s).\"));\n            } else {\n                return this.layers[index];\n            }\n        } else {\n            if (name == null) {\n                throw new _errors.ValueError('Provide either a layer name or layer index');\n            }\n        }\n        for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n            var layer = _a[_i];\n            if (layer.name === name) {\n                return layer;\n            }\n        }\n        throw new _errors.ValueError(\"No such layer: \" + name);\n    };\n    Container.prototype.calculateLosses = function () {\n        var _this = this;\n        return (0, _tfjsCore.tidy)(function () {\n            var losses = [];\n            for (var _i = 0, _a = _this.layers; _i < _a.length; _i++) {\n                var layer = _a[_i];\n                for (var nodeIndex = 0; nodeIndex < layer.inboundNodes.length; ++nodeIndex) {\n                    var nodeKey = Container.nodeKey(layer, nodeIndex);\n                    if (_this.containerNodes.has(nodeKey)) {\n                        losses.push.apply(losses, layer.calculateLosses());\n                    }\n                }\n            }\n            return losses;\n        });\n    };\n    Container.prototype.getConfig = function () {\n        var config = { name: this.name };\n        var nodeConversionMap = this.buildNodeConversionMap(this.layers);\n        var layerConfigs = [];\n        for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n            var layer = _a[_i];\n            var layerClassName = layer.getClassName();\n            var layerConfig = layer.getConfig();\n            var filteredInboundNodes = [];\n            for (var originalNodeIndex = 0; originalNodeIndex < layer.inboundNodes.length; originalNodeIndex++) {\n                var node = layer.inboundNodes[originalNodeIndex];\n                var nodeKey = Container.nodeKey(layer, originalNodeIndex);\n                var kwargs = {};\n                if (this.containerNodes.has(nodeKey)) {\n                    if (node.callArgs) {\n                        var testString = JSON.stringify(node.callArgs);\n                        if (testString.indexOf('undefined') === -1) {\n                            kwargs = node.callArgs;\n                        } else {\n                            console.warn(\"Layer \" + layer.name + \" was passed \" + \"non-serializable keyword arguments: \" + (node.callArgs + \". They will not be included \") + \"in the serialized model (and thus will be \" + \"missing at deserialization time).\");\n                            kwargs = {};\n                        }\n                    }\n                    if (node.inboundLayers.length > 0) {\n                        var nodeData = [];\n                        for (var i = 0; i < node.inboundLayers.length; i++) {\n                            var inboundLayer = node.inboundLayers[i];\n                            var nodeIndex = node.nodeIndices[i];\n                            var tensorIndex = node.tensorIndices[i];\n                            var nodeKey_1 = Container.nodeKey(inboundLayer, nodeIndex);\n                            var newNodeIndex = nodeConversionMap[nodeKey_1];\n                            if (newNodeIndex === null || newNodeIndex === undefined) {\n                                newNodeIndex = 0;\n                            }\n                            nodeData.push([inboundLayer.name, newNodeIndex, tensorIndex, kwargs]);\n                        }\n                        filteredInboundNodes.push(nodeData);\n                    }\n                }\n            }\n            layerConfigs.push({\n                name: layer.name,\n                className: layerClassName,\n                config: layerConfig,\n                inboundNodes: filteredInboundNodes\n            });\n        }\n        config['layers'] = layerConfigs;\n        var modelInputs = [];\n        for (var i = 0; i < this.inputLayers.length; i++) {\n            var layer = this.inputLayers[i];\n            var nodeIndex = this.inputLayersNodeIndices[i];\n            var nodeKey = Container.nodeKey(layer, nodeIndex);\n            if (!this.containerNodes.has(nodeKey)) {\n                continue;\n            }\n            var newNodeIndex = nodeConversionMap[nodeKey];\n            if (newNodeIndex === null || newNodeIndex === undefined) {\n                newNodeIndex = 0;\n            }\n            var tensorIndex = this.inputLayersTensorIndices[i];\n            modelInputs.push([layer.name, newNodeIndex, tensorIndex]);\n        }\n        config['inputLayers'] = modelInputs;\n        var modelOutputs = [];\n        for (var i = 0; i < this.outputLayers.length; i++) {\n            var layer = this.outputLayers[i];\n            var nodeIndex = this.outputLayersNodeIndices[i];\n            var nodeKey = Container.nodeKey(layer, nodeIndex);\n            if (!this.containerNodes.has(nodeKey)) {\n                continue;\n            }\n            var newNodeIndex = nodeConversionMap[nodeKey];\n            if (newNodeIndex === null || newNodeIndex === undefined) {\n                newNodeIndex = 0;\n            }\n            var tensorIndex = this.outputLayersTensorIndices[i];\n            modelOutputs.push([layer.name, newNodeIndex, tensorIndex]);\n        }\n        config['outputLayers'] = modelOutputs;\n        return config;\n    };\n    Container.fromConfig = function (cls, config) {\n        var createdLayers = {};\n        var unprocessedNodes = {};\n        function addUnprocessedNode(layer, nodeData) {\n            if (!(layer.name in unprocessedNodes)) {\n                unprocessedNodes[layer.name] = [nodeData];\n            } else {\n                unprocessedNodes[layer.name].push(nodeData);\n            }\n        }\n        function processNode(layer, nodeData) {\n            var inputTensors = [];\n            var kwargs;\n            for (var _i = 0, nodeData_1 = nodeData; _i < nodeData_1.length; _i++) {\n                var inputData = nodeData_1[_i];\n                var inboundLayerName = inputData[0];\n                var inboundNodeIndex = inputData[1];\n                var inboundTensorIndex = inputData[2];\n                if (inputData.length === 3) {\n                    kwargs = {};\n                } else if (inputData.length === 4) {\n                    kwargs = inputData[3];\n                } else {\n                    throw new _errors.ValueError(\"Improperly formatted model config for layer \" + JSON.stringify(layer) + \": \" + JSON.stringify(inputData));\n                }\n                if (!(inboundLayerName in createdLayers)) {\n                    addUnprocessedNode(layer, nodeData);\n                    return;\n                }\n                var inboundLayer = createdLayers[inboundLayerName];\n                if (inboundLayer.inboundNodes.length <= inboundNodeIndex) {\n                    addUnprocessedNode(layer, nodeData);\n                    return;\n                }\n                var inboundNode = inboundLayer.inboundNodes[inboundNodeIndex];\n                inputTensors.push(inboundNode.outputTensors[inboundTensorIndex]);\n            }\n            if (inputTensors.length > 0) {\n                layer.apply(generic_utils.singletonOrArray(inputTensors), kwargs);\n            }\n        }\n        function processLayer(layerData) {\n            var layerName = layerData.name;\n            var layer = (0, _serialization.deserialize)(layerData, config.customObjects != null ? config.customObjects : {});\n            createdLayers[layerName] = layer;\n            var inboundNodesData = layerData.inboundNodes;\n            for (var _i = 0, inboundNodesData_1 = inboundNodesData; _i < inboundNodesData_1.length; _i++) {\n                var nodeData = inboundNodesData_1[_i];\n                if (!(nodeData instanceof Array)) {\n                    throw new _errors.ValueError(\"Corrupted configuration, expected array for nodeData: \" + nodeData);\n                }\n                addUnprocessedNode(layer, nodeData);\n            }\n        }\n        var name = config.name;\n        var layersFromConfig = config.layers;\n        for (var _i = 0, layersFromConfig_1 = layersFromConfig; _i < layersFromConfig_1.length; _i++) {\n            var layerData = layersFromConfig_1[_i];\n            processLayer(layerData);\n        }\n        while (!generic_utils.isObjectEmpty(unprocessedNodes)) {\n            for (var _a = 0, layersFromConfig_2 = layersFromConfig; _a < layersFromConfig_2.length; _a++) {\n                var layerData = layersFromConfig_2[_a];\n                var layer = createdLayers[layerData.name];\n                if (layer.name in unprocessedNodes) {\n                    for (var _b = 0, _c = unprocessedNodes[layer.name]; _b < _c.length; _b++) {\n                        var nodeData = _c[_b];\n                        processNode(layer, nodeData);\n                    }\n                    delete unprocessedNodes[layer.name];\n                }\n            }\n        }\n        var inputTensors = [];\n        var outputTensors = [];\n        var inputLayersFromConfig = config.inputLayers;\n        for (var _d = 0, inputLayersFromConfig_1 = inputLayersFromConfig; _d < inputLayersFromConfig_1.length; _d++) {\n            var layerData = inputLayersFromConfig_1[_d];\n            var layerName = layerData[0];\n            var nodeIndex = layerData[1];\n            var tensorIndex = layerData[2];\n            generic_utils.assert(layerName in createdLayers);\n            var layer = createdLayers[layerName];\n            var layerOutputTensors = layer.inboundNodes[nodeIndex].outputTensors;\n            inputTensors.push(layerOutputTensors[tensorIndex]);\n        }\n        var outputLayersFromConfig = config.outputLayers;\n        for (var _e = 0, outputLayersFromConfig_1 = outputLayersFromConfig; _e < outputLayersFromConfig_1.length; _e++) {\n            var layerData = outputLayersFromConfig_1[_e];\n            var layerName = layerData[0];\n            var nodeIndex = layerData[1];\n            var tensorIndex = layerData[2];\n            generic_utils.assert(layerName in createdLayers);\n            var layer = createdLayers[layerName];\n            var layerOutputTensors = layer.inboundNodes[nodeIndex].outputTensors;\n            outputTensors.push(layerOutputTensors[tensorIndex]);\n        }\n        return new cls({ inputs: inputTensors, outputs: outputTensors, name: name });\n    };\n    Object.defineProperty(Container.prototype, \"stateful\", {\n        get: function () {\n            if (this._stateful) {\n                throw new _errors.ValueError('Container instance unexpectedly has _stateful = true. The ' + 'statefulness of a Container is determined by the Layers it ' + 'contains. Its _stateful property must remain the default false.');\n            }\n            for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n                var layer = _a[_i];\n                if (layer.stateful) {\n                    return true;\n                }\n            }\n            return false;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    __decorate([(0, _tfjsCore.doc)({\n        heading: 'Layers',\n        subheading: 'Classes',\n        namespace: 'layers',\n        subclasses: ['Model']\n    })], Container.prototype, \"getLayer\", null);\n    return Container;\n}(Layer);\nexports.Container = Container;\nfunction getSourceInputs(tensor, layer, nodeIndex) {\n    if (layer == null || nodeIndex != null && nodeIndex > 0) {\n        layer = tensor.sourceLayer;\n        nodeIndex = tensor.nodeIndex;\n    }\n    if (layer.inboundNodes.length === 0) {\n        return [tensor];\n    } else {\n        var node = layer.inboundNodes[nodeIndex];\n        if (node.inboundLayers.length === 0) {\n            return node.inputTensors;\n        } else {\n            var sourceTensors = [];\n            for (var i = 0; i < node.inboundLayers.length; i++) {\n                var x = node.inputTensors[i];\n                var layer_2 = node.inboundLayers[i];\n                var nodeIndex_3 = node.nodeIndices[i];\n                var previousSources = getSourceInputs(x, layer_2, nodeIndex_3);\n                for (var _i = 0, previousSources_1 = previousSources; _i < previousSources_1.length; _i++) {\n                    var x_1 = previousSources_1[_i];\n                    if (sourceTensors.indexOf(x_1) === -1) {\n                        sourceTensors.push(x_1);\n                    }\n                }\n            }\n            return sourceTensors;\n        }\n    }\n}\nfunction loadTensor(dtype, shape, value) {\n    var dataType = generic_utils.stringToDType(dtype);\n    return _tfjsCore.Tensor.make(shape, { values: shape.length === 0 ? value : _tfjsCore.util.flatten(value) }, dataType);\n}\nfunction preprocessWeightsForLoading(layer, weights, originalKerasVersion, originalBackend) {\n    if (!originalKerasVersion.startsWith('2.')) {\n        throw new _errors.ValueError('Unsupported Keras version in weights being loaded: ' + originalKerasVersion);\n    }\n    return weights;\n}\nfunction loadWeightsFromNamedTensorMap(weights, layers) {\n    var nameToWeight = {};\n    var totalWeightsCount = 0;\n    for (var _i = 0, layers_1 = layers; _i < layers_1.length; _i++) {\n        var layer = layers_1[_i];\n        for (var _a = 0, _b = layer.weights; _a < _b.length; _a++) {\n            var weight = _b[_a];\n            if (nameToWeight[weight.originalName] != null) {\n                throw new _errors.ValueError(\"Duplicate weight name: \" + weight.originalName);\n            }\n            nameToWeight[weight.originalName] = weight;\n            totalWeightsCount++;\n        }\n    }\n    var weightValueTuples = [];\n    for (var name_2 in weights) {\n        weightValueTuples.push([nameToWeight[name_2], weights[name_2]]);\n        delete nameToWeight[name_2];\n    }\n    var unsetNames = [];\n    for (var name_3 in nameToWeight) {\n        unsetNames.push(name_3);\n    }\n    if (unsetNames.length > 0) {\n        throw new _errors.ValueError(unsetNames.length + \" of \" + totalWeightsCount + \" weights are not set: \" + (\"\" + unsetNames));\n    }\n    (0, _variables.batchSetValue)(weightValueTuples);\n}\nfunction loadWeightsFromJson(weightsJSON, layers, skipMismatch) {\n    if (skipMismatch === void 0) {\n        skipMismatch = false;\n    }\n    var originalKerasVersion = weightsJSON['keras_version'];\n    var originalBackend = weightsJSON['backend'];\n    var layerNames = layers.map(function (layer) {\n        return layer.name;\n    });\n    var index = {};\n    for (var _i = 0, layers_2 = layers; _i < layers_2.length; _i++) {\n        var layer = layers_2[_i];\n        if (layer.name != null) {\n            if (index[layer.name] == null) {\n                index[layer.name] = [];\n            }\n            index[layer.name].push(layer);\n        }\n    }\n    var nameToWeights = weightsJSON['weights'];\n    var weightValueTuples = [];\n    for (var k = 0; k < layerNames.length; ++k) {\n        var name_4 = layerNames[k];\n        var layerWeights = nameToWeights[name_4];\n        if (layerWeights == null) {\n            layerWeights = [];\n        }\n        var weightValues = [];\n        for (var n = 0; n < layerWeights.length; ++n) {\n            var weightEntry = layerWeights[n];\n            weightValues.push(new _variables.LayerVariable(loadTensor(weightEntry['dtype'], weightEntry['shape'], weightEntry['value'])));\n        }\n        for (var _a = 0, _b = index[name_4]; _a < _b.length; _a++) {\n            var layer = _b[_a];\n            var symbolicWeights = layer.weights;\n            weightValues = preprocessWeightsForLoading(layer, weightValues, originalKerasVersion, originalBackend);\n            if (weightValues.length !== symbolicWeights.length) {\n                if (skipMismatch) {\n                    console.warn(\"Skipping loading of weights of layer \" + layer.name + \" \" + (\"due to mismatch in number of weights: (\" + weightValues.length + \" \") + (\"vs \" + symbolicWeights.length + \").\"));\n                } else {\n                    throw new _errors.ValueError(\"Layer #\" + k + \" (named \\\"\" + layer.name + \"\\\") expects \" + (symbolicWeights.length + \" weight(s), but the saved weights \") + (\"have \" + weightValues.length + \" element(s).\"));\n                }\n            }\n            for (var i = 0; i < weightValues.length; ++i) {\n                if (skipMismatch) {\n                    if (!_tfjsCore.util.arraysEqual(symbolicWeights[i].shape, weightValues[i].shape)) {\n                        console.warn(\"Skipping loading of weights for layer \" + layer.name + \" due \" + (\"to mismatch in shape (\" + symbolicWeights[i].shape + \" vs \") + (weightValues[i].shape + \")\"));\n                        continue;\n                    }\n                }\n                weightValueTuples.push([symbolicWeights[i], weightValues[i].read()]);\n            }\n        }\n    }\n    (0, _variables.batchSetValue)(weightValueTuples);\n}\n//# sourceMappingURL=topology.js.map"},"hash":"fbade89e6aecf5d62b83f49fa41fd6f8","cacheData":{"env":{}}}